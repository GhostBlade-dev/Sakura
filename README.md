# ğŸ—£ï¸ Conversational Agent ğŸ¤–

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![Node.js](https://img.shields.io/badge/Node.js-18%2B-green.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-teal.svg)
![Express](https://img.shields.io/badge/Express-Node.js-lightgrey.svg)

A voice-based conversational agent that lets users interact with an AI assistant using speech!  
The system records user audio, transcribes it, sends the transcript to a large language model (Gemini), and synthesizes the response using Murf AI text-to-speech.  
The frontend is a modern web UI, and the backend is built with FastAPI (Python) and Express (Node.js).

---

## ğŸš€ Technologies Used

- **Frontend:** HTML, CSS, JavaScript ([index.html](index.html)) ğŸ¨
- **Backend (Python):** FastAPI, gTTS, requests, AssemblyAI, Gemini API, Murf AI API ([audio_server.py](audio_server.py)) ğŸ
- **Backend (Node.js):** Express, node-fetch ([server.js](server.js)) ğŸŸ©
- **Other:** AssemblyAI for transcription, Murf AI for TTS, Gemini for LLM ğŸ§ 

---

## ğŸ—ï¸ Architecture

- **Frontend:**  
  - ğŸ¤ Records audio from the user.
  - ğŸ“¤ Sends audio to the backend for processing.
  - ğŸ’¬ Displays chat history and plays synthesized responses.

- **Backend (Python):**  
  - ğŸ“¥ Handles audio uploads and session-based chat.
  - ğŸ“ Transcribes audio using AssemblyAI.
  - ğŸ—‚ï¸ Maintains chat history per session.
  - ğŸ¤– Sends chat history to Gemini LLM for context-aware responses.
  - ğŸ”Š Synthesizes responses using Murf AI TTS.
  - ğŸ—ƒï¸ Serves static files and uploaded audio.

- **Backend (Node.js):**  
  - ğŸŸ© Provides an Express server for Murf AI TTS generation (optional).

---

## âœ¨ Features

- ğŸ—£ï¸ Voice-based conversational interface
- ğŸ§  Session-based chat history for context retention
- âš¡ Real-time transcription and LLM response
- ğŸ”Š High-quality TTS synthesis
- ğŸ›¡ï¸ Fallback to gTTS or browser TTS if Murf AI fails
- ğŸ–¥ï¸ Modern, responsive UI

---

## ğŸ“¸ Screenshots

| Chat UI | Audio Upload |
|--------|-------------|
| ![Chat UI](https://user-images.githubusercontent.com/placeholder/chat-ui.png) | ![Audio Upload](https://user-images.githubusercontent.com/placeholder/audio-upload.png) |

*Replace the above URLs with your actual screenshots!*

---

## ğŸ› ï¸ Setup & Running

### ğŸ“‹ Prerequisites

- Python 3.8+
- Node.js 18+
- [pip](https://pip.pypa.io/en/stable/)

### ğŸ”‘ Environment Variables

Set the following environment variables (or update them directly in [`audio_server.py`](audio_server.py)):
- `GEMINI_API_KEY` (Google Gemini API key)
- `ASSEMBLYAI_API_KEY` (AssemblyAI API key)
- `MURF_API_KEY` (Murf AI API key)

You can export them in your shell or use a `.env` file.

### ğŸ“¦ Install Python Dependencies

```sh
pip install fastapi uvicorn gtts requests
```

### ğŸ“¦ Install Node.js Dependencies

```sh
npm install
```

### â–¶ï¸ Run the Python API Server

```sh
uvicorn audio_server:app --host 0.0.0.0 --port 8000
```

### â–¶ï¸ Run the Node.js Server (optional, for Murf AI TTS only)

```sh
node server.js
```

### ğŸŒ Access the Frontend

Open [http://localhost:8000](http://localhost:8000) in your browser.

---

## ğŸ“¡ API Endpoints

- `POST /agent/chat/{session_id}`: Upload audio, get LLM response and TTS audio
- `POST /tts/gtts`: Synthesize text using gTTS (fallback)
- `POST /tts/murf`: Synthesize text using Murf AI
- `POST /upload-audio`: Upload audio file
- `GET /uploads/{filename}`: Serve uploaded audio
- `GET /`: Serve frontend

See [`audio_server.py`](audio_server.py) for full API details.

---

## ğŸ“ Notes

- ğŸ“ Uploaded audio and synthesized files are stored in the `uploads/` directory.
- ğŸ§  The system uses in-memory chat history per session; restarting the server clears history.
- ğŸ”’ For production, secure your API keys and use HTTPS.

---

## ğŸ“„ License

MIT License